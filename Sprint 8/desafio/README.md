# üß© Desafio da Sprint 8
Este diret√≥rio cont√©m os arquivos necess√°rios para a realiza√ß√£o do desafio desta Sprint.

___

## üìù Enunciado
O desafio da Sprint 8 √© uma continua√ß√£o do desafio iniciado na Sprint 6, sendo a terceira entrega do desafio final.

Esta etapa consiste no **processamento da camada *trusted***, com essa possuindo os dados limpos e confi√°veis. Consiste na integra√ß√£o das diversas fontes de origem (dados que est√£o na camada Raw).

Ser√° utilizado Apache Spark atrav√©s do servi√ßo AWS Glue, integrando dados existentes na camada *Raw Zone* para a *Trusted Zone*. Todos os dados da *Trusted Zone* devem possuir o mesmo formato de armazenamento e poder ser analisados no AWS Athena por meio de SQL.

Os dados ser√£o persistidos no formato PARQUET, particionados por data de cria√ß√£o do arquivo no momento da ingest√£o do dado da TMDB. A exce√ß√£o fica para os dados oriundos do processamento *batch* (CSV), que n√£o precisam ser particionados.

Iremos separar o processamento em dois jobs:
1. Processamento dos arquivos CSV
2. Processamento dos dados oriundos da API TMDB.

> OBS.: N√£o utilizar notebooks do Glue.


## Resolu√ß√£o

### 1. Cria√ß√£o e permiss√µes de usu√°rio IAM

Na Sprint anterior, no exerc√≠cio Lab AWS Glue, tivemos de criar um usu√°rio IAM para fornecer permiss√µes e realizar as opera√ß√µes necess√°rias. No entanto, ao encerrar a Sprint, exclu√≠ todos os recursos criados por mim durante a Sprint, necessitando agora criar outro usu√°rio IAM.

Sendo assim, criei o usu√°rio e configurei a *Role* para o Glue.

![Imagem cria√ß√£o IAM user](../evidencias/ev_desafio/1-usuarioIAM.png)

![Imagem configura√ß√£o IAM Role](../evidencias/ev_desafio/1.1-configRole1.png)

![Imagem configura√ß√£o IAM Role 2](../evidencias/ev_desafio/1.2-configRole2.png)

### 2. Configura√ß√µes de permiss√µes no AWS Lake Formation

**2.1. Cria√ß√£o de *Database***

![Imagem cria√ß√£o database](../evidencias/ev_desafio/2-criacaoDatabase.png)

**2.2. Adi√ß√£o do usu√°rio IAM como Administrador do *data lake***

![Imagem configura√ß√£o Administrador data lake](../evidencias/ev_desafio/2.1-confLakeFormation.png)

**2.3. Altera√ß√£o de permiss√µes do *Database***

![Imagem altera√ß√£o de permiss√µes do database](../evidencias/ev_desafio/2.2-grantPermissions.png)

### 3. Cria√ß√£o dos jobs

Cada um dos jobs fica respons√°vel por dados ingeridos de maneira distinta:

- **job-batch-data**: dados CSV processados em lote (Sprint 6).

![Imagem cria√ß√£o job dados ingest√£o Batch](../evidencias/ev_desafio/3-criacaoJobBatch.png)

- **job-tmdb-data**: dados JSON ingeridos da API do TMDB (Sprint 7).

![Imagem cria√ß√£o job dados API TMDB](../evidencias/ev_desafio/3.1-criacaoJobTMDB.png)


![Imagem jobs AWS Glue](../evidencias/ev_desafio/3.2-jobsCriados.png)

Por conseguinte, foi necess√°rio alterar os par√¢metros com os locais de busca dos arquivos Raw e de salvamento dos arquivos na camada Trusted.

![Imagem altera√ß√£o de par√¢metros para Script](../evidencias/ev_desafio/3.3-alteracaoParametros.png)

### 4. Desenvolvimento dos Scripts

### 4.1. Script dados *Batch*


### 4.2. Script dados API TMDB


### 5. Cria√ß√£o de Crawler

Depois, necessitamos criar um Crawler para criar uma tabela a partir dos dados do S3 automaticamente.

![Imagem cria√ß√£o Crawler 1](../evidencias/ev_desafio/5-criandoCrawler.png)

![Imagem cria√ß√£o Crawler 2 - definindo dataSource](../evidencias/ev_desafio/5.1-crawlerDataSource.png)

![Imagem cria√ß√£o Crawler 3](../evidencias/ev_desafio/5.2-criandoCrawlerFinal.png)

### 6. Evid√™ncias execu√ß√£o



___

### ‚Ü©Ô∏è [Retornar ao in√≠cio](../../README.md)