# üß© Desafio da Sprint 6
Este diret√≥rio cont√©m os arquivos necess√°rios para a realiza√ß√£o do desafio desta Sprint.

## Quest√µes para An√°lise 

## üìù Enunciado(s)
O desafio da Sprint 6 consiste na primeira entrega do desafio final, o qual ter√° cinco (5) sprints de dura√ß√£o (da 6¬™ at√© a 10¬™).

Nesta sprint, devemos realizar a ingest√£o *batch* (em lote) dos arquivos CSV em um Bucket Amazon S3 RAW Zone.

Devemos desenvolver um c√≥digo Python que ser√° executado dentro de um container Docker para carregar os dados locais para a nuvem. Ser√° amplamente utilizada a biblioteca `boto3` para a realiza√ß√£o dessa etapa do desafio.

A imagem abaixo ilustra o que ser√° realizado nessa primeira etapa do desafio.


![Imagem desafio](../evidencias/ev_desafio/0_imagem_desafio.png)

1. O c√≥digo Python deve:
- **Ler** os dois (filmes e s√©ries) no formato CSV **sem filtrar os dados**.
- Utilizar a lib **`boto3`** para **carregar os dados para a AWS**.
- Acessar a AWS e **gravar no S3**, no **bucket definido com RAW Zone**.
    - Na grava√ß√£o dos dados, deve-se considerar o padr√£o: `<nome-do-bucket>\<camada-de-armazenamento>\<origem-dado>\<formato-do-dado>\<especifica√ß√£o-do-dado>\<data-do-processamento ano\mes\dia>\<arquivo>`.
        - Exemplo: `S3:\\data-lake\Raw\Local\CSV\Movies\2024\09\03\movies.csv` & `S3:\\data-lake\Raw\Local\CSV\Series\2024\09\03\series.csv`

2. Criar container Docker com um volume para armazenar os arquivos CSV e executar processo Python implementado.
3. Executar localmente o container Docker para realizar a carga dos dados ao S3.


___

### ‚Ü©Ô∏è [Retornar ao in√≠cio](../../README.md)