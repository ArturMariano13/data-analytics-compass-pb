# üß© Desafio da Sprint 5
Este diret√≥rio cont√©m os arquivos necess√°rios para a realiza√ß√£o do desafio desta Sprint.

## üìù Enunciado(s)
1. Procure um arquivo CSV ou JSON no portal de dados p√∫blicos do Governo Brasileiro: [link](http://dados.gov.br)
    - Garanta que seu arquivo seja √∫nico na turma;
    - Certifique-se de que n√£o excedeu nenhum limite do S3 de acordo com a documenta√ß√£o do mesmo.

2. Analise o conjunto de dados escolhido localmente em editor de texto para conhecer os dados e o que pode ser analisado.

3. Carregue o arquivo para um *bucket* novo, para executar o desafio.

4. Voc√™ pode utilizar o **Console** (nota at√© 80%) ou desenvolver um c√≥digo Python usando **Boto3** (nota at√© 100%) para fazer uso do S3 Select.

5. Atrav√©s da fun√ß√£o **S3 Select** crie pelo menos uma consulta no seu arquivo que utilize:
    1. Uma cl√°usula que filtra dados usando ao menos dois operadores l√≥gicos
    2. Duas fun√ß√µes de agrega√ß√£o
    3. Uma fun√ß√£o condicional
    4. Uma fun√ß√£o de convers√£o
    5. Uma fun√ß√£o de data
    6. Uma fun√ß√£o de string

OBS.: menos consultas = maior avalia√ß√£o

6. Armazenar no Git um arquivo Markdown explicando seu conjunto de Dados, bem como sua(s) consulta(s) e o resultado das execu√ß√µes de suas consultas.
    - Armazenar a(s) consultas em arquivo(s) *.sql*
    - Armazenar o(s) arquivo(s) de c√≥digo em arquivo(s) *.py*
    - Armazenar as evid√™ncias de execu√ß√£o com imagens *.jpeg* ou *.png*

## Resposta(s)
### 1. Escolha do conjunto de dados
Selecionei a base de dados da pol√≠cia federal com diversas opera√ß√µes realizadas em diferentes datas, com foco em tipos espec√≠ficos de crimes e atividades.
- **Site do governo:** [link](https://dados.gov.br/dados/conjuntos-dados/palas---sistema-de-informacoes-de-investigacao)
- **Arquivo baixado:** [link](PALAS_OPERACOES_2024_01.csv)

### 2. An√°lise do conjunto de dados selecionado
- Markdown com an√°lise do dataset: [Arquivo](analise_dados.md)

### 3. Carregar arquivo para bucket novo
Explicar processo de cria√ß√£o do bucket, carregamento...

### 4, 5. Cria√ß√£o do script Python com as consultas
**1¬∫ passo:** instalar biblioteca Boto3: `pip install boto3`
<p align="center">
  <img src="../evidencias/1_boto3_install.png" alt="Instala√ß√£o Boto3">
</p>

**2¬∫ passo:** configurar AWS.
- Instalar AWS CLI.
- Comando: `aws configure`
    - Inserir credenciais para comunicar com a conta da AWS.
    - Isso n√£o funcionou de primeira, por isso necessitei alterar o arquivo credentials dentro do diret√≥rio .aws.
    - Conforme na seguinte evid√™ncia: [configura√ß√£o](../evidencias/3_config_credentials_correct.png), editei o arquivo credentials, necessitando adicionar a linha com o token da sess√£o.
        <p align="center">
        <img src="../evidencias/3_config_credentials_correct.png" alt="Configura√ß√£o credenciais AWS">
        </p>

**3¬∫ passo:** criar *bucket* e fazer upload do arquivo.
    - **Cria√ß√£o:** desenvolvi um script que realizava essa tarefa, inseri o c√≥digo separado no diret√≥rio de evid√™ncias ([ver c√≥digo](../evidencias/criar_bucket.py)).
    - **Upload:** tamb√©m desenvolvi um script ([veja aqui](../evidencias/upload_csv.py)) que realiza essa tarefa. 

**4¬∫ passo:** desenvolver script para a realiza√ß√£o de consultas.
    - Primeiramente, tamb√©m desenvolvi um script apenas para a realiza√ß√£o da consulta, na qual utilizei todos os requisitos do desafio [ver c√≥digo](../evidencias/main.py).
    - Como pode-se perceber na linha 39 do script, a consulta est√° armazenada no arquivo sql [query.sql](query.sql), e o script criado faz a leitura do arquivo recebendo o que est√° escrito em seu interior.
    - Ap√≥s isso realizado, julguei ser melhor modularizar o c√≥digo e unir tudo em um s√≥, criando o novo [script](script.py).

- C√≥digo final: [ver](script.py)

## Explica√ß√£o detalhada do Script desenvolvido
### 1. Bibliotecas utilizadas

<p align="center">
    <img src="../evidencias/COD1_bibliotecas.png" alt="Importa√ß√£o das bibliotecas">
</p>

- **boto3:** para interagir com o servi√ßo S3 da AWS. Nesse caso, √© usada para criar buckets S3, fazer upload de arquivos, e executar consultas em arquivos armazenados no S3.
- **logging:** biblioteca utilizada para gerar logs em aplicativos Python. Foi usada aqui para registrar erros durante opera√ß√µes AWS.
- **botocore.exceptions:** no script, ClientError √© usada para capturar e tratar erros ao criar buckets ou fazer uploads no S3.
- **os:** usada para manipular nomes de arquivos e caminhos.
- **pandas:** usada para carregar, processar, e salvar arquivos CSV, incluindo limpeza de dados e formata√ß√£o de colunas.
- **re:** usada para limpar espa√ßos e padronizar strings nos dados.
- **chardet:** usada para identificar a codifica√ß√£o de arquivos CSV antes de carreg√°-los com pandas, garantindo que caracteres sejam lidos corretamente.

> As bibliotecas essenciais para o desafio s√£o a "boto3" e "pandas", as outras utilizei devido a diversos fatores: entender os erros que estavam surgindo, manipular arquivos do Sistema Operacional e identificar codifica√ß√£o, que n√£o l√™ caracteres especiais como '√ß' e '~'. 


### 2. Cria√ß√£o do Bucket

<p align="center">
    <img src="../evidencias/COD2_criacao_bucket.png" alt="Chamada fun√ß√µes de cria√ß√£o Bucket">
    <img src="../evidencias/COD3_criacao_verificacao_bucket.png" alt="Fun√ß√µes de verifica√ß√£o e cria√ß√£o do Bucket">
</p>

Como pode ser percebido nas imagens acima, no interior do m√©todo de processamento do arquivo o programa verifica se o bucket n√£o existe e posteriormente cria, ou n√£o, o Bucket desejado.

### 3. Ajuste do arquivo
Posterior √† cria√ß√£o do Bucket, necessitamos fazer o upload do arquivo para o S3. No entanto, primeiramente foi necess√°rio fazer uma visualiza√ß√£o em editor de texto (utilizei o Excel) para identificar poss√≠veis erros e ajustes necess√°rios.

Conforme explicitado no arquivo Markdown da an√°lise da base dados ([ver aqui](analise_dados.md)), necessitou-se **remover v√≠rgulas** de valores num√©ricos, substituindo por pontos, al√©m de **remover o 'R$'** - isso na coluna **'Qtd Prejuizos Causados a Uniao'**.

<p align="center">
    <img src="../evidencias/COD4_correcoes_dados.png" alt="Corre√ß√£o da base de dados para envio ao S3">
</p>

Ao final, o arquivo √© salvo no diret√≥rio atual para posterior envio ao Bucket.

### 4. Envio ao Bucket S3
<p align="center">
    <img src="../evidencias/COD5_upload_arquivo.png" alt="Envio da base de dados ao S3">
</p>

Na imagem acima, podemos perceber a chamada da fun√ß√£o acima, e a implementa√ß√£o dela abaixo, enviando assim o arquivo corrigido para o Bucket S3.

### 5. Realiza√ß√£o da consulta ao arquivo
Primeiramente, a consulta est√° em um arquivo .sql ([ver arquivo](query.sql)), o qual deve ser lido no script e depois passado como *Expression* para realizar a consulta. A imagem abaixo mostra a leitura do arquivo e a chamada do m√©todo que realiza a query.

<p align="center">
    <img src="../evidencias/COD6_consulta_1.png" alt="Leitura do arquivo e chamada do m√©todo">
</p>

Posteriormente, o m√©todo que realiza efetivamente a consulta pode ser observado na imagem abaixo. Faz-se necess√°rio receber o nome do Bucket, da chave (nome do arquivo) e a query (que foi passada por par√¢metro).

<p align="center">
    <img src="../evidencias/COD7_consulta_2.png" alt="Realiza√ß√£o da consulta">
</p>

### 6. Resultados da execu√ß√£o do script
**6.1. Primeira execu√ß√£o do script**

<p align="center">
    <img src="../evidencias/COD8_primeira_execucao.png" alt="Resultado da primeira execu√ß√£o">
</p>


**6.2. Execu√ß√µes seguintes**

<p align="center">
    <img src="../evidencias/COD9_outras_execucoes.png" alt="Resultado de outras execu√ß√µes">
</p>

___

### ‚Ü©Ô∏è [Retornar ao in√≠cio](../../README.md)